{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/System_engineering/blob/main/Ragas.ipynb",
      "authorship_tag": "ABX9TyO/xrqroNYHTnjMFd+NiP64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c92422b583aa4010b1adb3060074bfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d079541ded604e59913f6959a34e8e18",
              "IPY_MODEL_f11aa6a81aaf440292c3a6082c29e761",
              "IPY_MODEL_fa270b9b39b440b8885d01b51b717453"
            ],
            "layout": "IPY_MODEL_d780641b3dec468bb18e36b67f94ffe1"
          }
        },
        "d079541ded604e59913f6959a34e8e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02511d4fd6434eb9814a09c4cec7fe6f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_320b3c4d4c5d48c1b18b29235f3e5c09",
            "value": "Evaluating:â€‡100%"
          }
        },
        "f11aa6a81aaf440292c3a6082c29e761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4a6d99dcc243f582bb6c6d06a59cc5",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_060e1241eb844a399bb9ce5eddf48973",
            "value": 200
          }
        },
        "fa270b9b39b440b8885d01b51b717453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6286e1a2a836483b8414069555ac2862",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_84e53e5b77c14e97b3dc0c4bfa52fdbf",
            "value": "â€‡200/200â€‡[01:56&lt;00:00,â€‡â€‡1.33s/it]"
          }
        },
        "d780641b3dec468bb18e36b67f94ffe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02511d4fd6434eb9814a09c4cec7fe6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320b3c4d4c5d48c1b18b29235f3e5c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a4a6d99dcc243f582bb6c6d06a59cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "060e1241eb844a399bb9ce5eddf48973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6286e1a2a836483b8414069555ac2862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e53e5b77c14e97b3dc0c4bfa52fdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/System_engineering/blob/main/Ragas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.ragas.io/en/v0.1.21/concepts/metrics/answer_relevance.html"
      ],
      "metadata": {
        "id": "X4xrumCCkYaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_openai ragas"
      ],
      "metadata": {
        "id": "INgzXSgXhoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI\n",
        "from ragas import evaluate, EvaluationDataset\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import (\n",
        "    AnswerRelevancy,\n",
        "    Faithfulness,\n",
        "    FactualCorrectness,\n",
        "    AnswerCorrectness\n",
        ")\n",
        "\n",
        "# OpenAI API AnahtarÄ±nÄ± Ayarla\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk\"\n",
        "\n",
        "# Excel dosyasÄ±nÄ± oku (B sÃ¼tununda sorular, C sÃ¼tununda referans cevaplar, D sÃ¼tununda deepseek-r1 cevaplarÄ±)\n",
        "df = pd.read_excel(\"/content/Veri KarÅŸÄ±laÅŸtÄ±rma_test.xlsx\")  # Dosya yolunuza gÃ¶re gÃ¼ncelleyiniz\n",
        "\n",
        "# KolonlarÄ± uygun deÄŸiÅŸkenlere alalÄ±m\n",
        "questions = df.iloc[:, 1].tolist()\n",
        "reference_answers = df.iloc[:, 2].tolist()\n",
        "deepseek_answers = df.iloc[:, 3].tolist()\n",
        "\n",
        "# LLM Modelini BaÅŸlat\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")  # GPT-4o deÄŸerlendirme iÃ§in kullanÄ±lacak\n",
        "evaluator_llm = LangchainLLMWrapper(llm)\n",
        "\n",
        "# DeÄŸerlendirme iÃ§in veri setini oluÅŸtur\n",
        "dataset = []\n",
        "for question, deepseek_response, reference in zip(questions, deepseek_answers, reference_answers):\n",
        "    dataset.append(\n",
        "        {\n",
        "            \"user_input\": question,\n",
        "            \"retrieved_contexts\": [],  # BaÄŸlam kullanmadÄ±ÄŸÄ±mÄ±z iÃ§in boÅŸ liste\n",
        "            \"response\": deepseek_response,\n",
        "            \"reference\": reference\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Dataset'i Ragas ile formatla\n",
        "evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
        "\n",
        "# Ragas deÄŸerlendirmesini gerÃ§ekleÅŸtir\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[\n",
        "        AnswerRelevancy(),\n",
        "        Faithfulness(),\n",
        "        FactualCorrectness(),\n",
        "        AnswerCorrectness()\n",
        "    ],\n",
        "    llm=evaluator_llm\n",
        ")\n",
        "\n",
        "# SonuÃ§larÄ± yazdÄ±r\n",
        "print(\"\\n--- DeepSeek-r1 DeÄŸerlendirme SonuÃ§larÄ± (ChatGPT-4o Referans Olarak KullanÄ±ldÄ±) ---\\n\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "c92422b583aa4010b1adb3060074bfd3",
            "d079541ded604e59913f6959a34e8e18",
            "f11aa6a81aaf440292c3a6082c29e761",
            "fa270b9b39b440b8885d01b51b717453",
            "d780641b3dec468bb18e36b67f94ffe1",
            "02511d4fd6434eb9814a09c4cec7fe6f",
            "320b3c4d4c5d48c1b18b29235f3e5c09",
            "9a4a6d99dcc243f582bb6c6d06a59cc5",
            "060e1241eb844a399bb9ce5eddf48973",
            "6286e1a2a836483b8414069555ac2862",
            "84e53e5b77c14e97b3dc0c4bfa52fdbf"
          ]
        },
        "id": "5sgd1i06gheB",
        "outputId": "ea4009fe-da77-48e4-bc0c-a56a79e5f208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c92422b583aa4010b1adb3060074bfd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DeepSeek-r1 DeÄŸerlendirme SonuÃ§larÄ± (ChatGPT-4o Referans Olarak KullanÄ±ldÄ±) ---\n",
            "\n",
            "{'answer_relevancy': 0.8458, 'faithfulness': 0.0200, 'factual_correctness(mode=f1)': 0.2492, 'answer_correctness': 0.4218}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ä°lk 3 elemanÄ± yazdÄ±rma\n",
        "print(\"Questions - Ä°lk 3 SatÄ±r:\", questions[:3])\n",
        "print(\"Reference Answers - Ä°lk 3 SatÄ±r:\", reference_answers[:3])\n",
        "print(\"DeepSeek Answers - Ä°lk 3 SatÄ±r:\", deepseek_answers[:3])\n",
        "\n",
        "# Son 3 elemanÄ± yazdÄ±rma\n",
        "print(\"\\nQuestions - Son 3 SatÄ±r:\", questions[-3:])\n",
        "print(\"Reference Answers - Son 3 SatÄ±r:\", reference_answers[-3:])\n",
        "print(\"DeepSeek Answers - Son 3 SatÄ±r:\", deepseek_answers[-3:])\n"
      ],
      "metadata": {
        "id": "LjsGQ0Nbk8QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7381f2f-9b70-4d13-e54b-4edef07f8749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions - Ä°lk 3 SatÄ±r: ['Sistem mÃ¼hendisliÄŸi nedir ve temel amacÄ± nedir?', 'V-Model (V-ÅžemasÄ±) nedir ve hangi aÅŸamalarÄ± iÃ§erir?', 'â€œSistem gereksinimleriâ€ ile â€œkullanÄ±cÄ± gereksinimleriâ€ arasÄ±ndaki fark nedir?']\n",
            "Reference Answers - Ä°lk 3 SatÄ±r: ['Sistem mÃ¼hendisliÄŸi, karmaÅŸÄ±k sistemlerin tasarÄ±m, geliÅŸtirme, entegrasyon ve yaÅŸam dÃ¶ngÃ¼sÃ¼ yÃ¶netimiyle ilgilenen disiplinler arasÄ± bir alanÄ±dÄ±r. Temel amacÄ±, sistemleri en verimli ÅŸekilde tasarlamak, sÃ¼rekliliÄŸini saÄŸlamak ve uÃ§tan uca yÃ¶netmektir.', 'V-Model, sistem veya yazÄ±lÄ±m geliÅŸtirme yaÅŸam dÃ¶ngÃ¼sÃ¼nÃ¼ tanÄ±mlamak iÃ§in kullanÄ±lan bir modeldir. Sol kolunda gereksinim analizi ve tasarÄ±m faaliyetleri, saÄŸ kolunda ise test ve doÄŸrulama faaliyetleri bulunur. Ortada entegrasyon aÅŸamasÄ± yer alÄ±r ve sÃ¼reÃ§, gereksinimlerden doÄŸrulamaya kadar sistematik bir biÃ§imde ilerler.', 'Sistem gereksinimleri, bir sistemin teknik ve iÅŸlevsel niteliklerini tanÄ±mlar ve tasarÄ±m ekibi tarafÄ±ndan anlaÅŸÄ±lmasÄ± gereken ayrÄ±ntÄ±larÄ± iÃ§erir. KullanÄ±cÄ± gereksinimleri ise sistemin son kullanÄ±cÄ± tarafÄ±ndan nasÄ±l kullanÄ±lacaÄŸÄ±nÄ±, hangi amaÃ§lara hizmet etmesi gerektiÄŸini ve kullanÄ±cÄ± deneyimi ile ilgili beklentileri belirtir. Sistem gereksinimleri Ã§oÄŸunlukla mÃ¼hendisler iÃ§indir, kullanÄ±cÄ± gereksinimleri ise iÅŸ birimleri ve son kullanÄ±cÄ±lar iÃ§in formÃ¼le edilir.']\n",
            "DeepSeek Answers - Ä°lk 3 SatÄ±r: ['Sistem mÃ¼hendisliÄŸi, kullanÄ±cÄ±larÄ±n ihtiyaÃ§larÄ±nÄ± karÅŸÄ±layacak ÅŸekilde tasarlanmÄ±ÅŸ bir sistemin oluÅŸturulmasÄ±nÄ± saÄŸlayan disiplindir. Bu disipline gÃ¶re sistemlerin gereksinimleri belirlenir, tasarÄ±m yapÄ±lÄ±r, entegrasyon saÄŸlanÄ±r ve bakÄ±mÄ± da saÄŸlanarak sistemin baÅŸarÄ±lÄ± bir ÅŸekilde Ã§alÄ±ÅŸmasÄ± hedeflenir. Sistem mÃ¼hendisliÄŸinin temel amacÄ± ise verimli, gÃ¼venilir ve maliyet etkin Ã§Ã¶zÃ¼mler Ã¼retmek iÃ§in disiplinler arasÄ± bir yaklaÅŸÄ±mla iÅŸbirliÄŸini saÄŸlamak ve sÃ¼reÃ§leri optimize etmektir. Bu sayede karmaÅŸÄ±k sistemlerin baÅŸarÄ±lÄ± bir ÅŸekilde hayata geÃ§irilmesi ve kullanÄ±cÄ±lara faydalÄ± hizmet sunulmasÄ± amaÃ§lanmaktadÄ±r. \\nBu doÄŸrultuda, sistem mÃ¼hendisliÄŸi uygulamalarÄ±nda genellikle proje planlamasÄ± yapma, gereksinim analizi, tasarÄ±m, entegrasyon, testlama ve bakÄ±m gibi adÄ±mlar yer alÄ±r. AyrÄ±ca, farklÄ± disiplinerlerden gelen uzmanlar arasÄ±nda etkili iletiÅŸim ve koordinasyon saÄŸlanmalÄ±dÄ±r. Bu sayede, projenin her aÅŸamasÄ±nda tutarlÄ±lÄ±k ve kalite korunabilir. Sisteme Entegre EdilmiÅŸ Sistem AnalitiÄŸi (ISE) gibi araÃ§larla de bu sÃ¼recin daha kapsamlÄ± bir ÅŸekilde yÃ¶netilebilmesi mÃ¼mkÃ¼n olur. Son olarak, sÃ¼rekli Ã¶ÄŸrenmeyi teÅŸvik etmek ve ekip iÃ§i iletiÅŸimi gÃ¼Ã§lendirmek de sistem mÃ¼hendisliÄŸinde Ã¶nemli rol oynar. Bu sayede, sektÃ¶rde yenilikÃ§i Ã§Ã¶zÃ¼mlerin ortaya Ã§Ä±kmasÄ± ve rekabet avantajÄ±nÄ±n elde edilmesi saÄŸlanÄ±r. Bu nedenle, sistem mÃ¼hendisliÄŸi sadece teknik becerilerin bir toplamÄ± deÄŸil aynÄ± zamanda disiplinlerarasÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ±n Ã¼rÃ¼nÃ¼dÃ¼r. Bu disiplinin uygulanmasÄ± sayesinde, karmaÅŸÄ±k sistemlerin baÅŸarÄ±yla hayata geÃ§irilmesi ve uzun Ã¶mrÃ¼ boyunca sÃ¼rdÃ¼rÃ¼lebilir bir ÅŸekilde iÅŸletilmesi mÃ¼mkÃ¼n hale gelir. Bu nedenle, sistem mÃ¼hendisliÄŸi bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r ve birÃ§ok alanda uygulama alanÄ± bulmuÅŸtÃ¼r. Bu sayeden, sistem mÃ¼hendisliÄŸi yalnÄ±zca teknolojik ilerlemeyi desteklemekle kalmaz, aynÄ± zamanda insan faktÃ¶rÃ¼ne ve Ã§evresel etkilere de dikkat ederek daha iyi bir dÃ¼nya yaratmaya katkÄ±da bulunur. Bu dÃ¼ÅŸÃ¼nceler, sistem mÃ¼hendisliÄŸinin Ã¶nemi hakkÄ±nda Ã¶nemli bilgiler saÄŸlar.  \\nSonuÃ§ olarak, sistem mÃ¼hendisliÄŸi, karmaÅŸÄ±k sistemlerin tasarÄ±mÄ± ve yÃ¶netimi konusunda uzmanlaÅŸmÄ±ÅŸ bir disiplidir. Bu disilin amacÄ±, kullanÄ±cÄ±larÄ±n ihtiyaÃ§larÄ±na uygun Ã§Ã¶zÃ¼mleri Ã¼retmek, sistemi gÃ¼venli ve ekonomik bir ÅŸekilde iÅŸletmek, sÃ¼rekli iyileÅŸtirme yapmak ve bÃ¶ylece kullanÄ±cÄ±larÄ±n memnuniyetini artÄ±rarak baÅŸarÄ±sÄ±nÄ± saÄŸlamaktadÄ±r.', \"The V-Model (V Åžekli) generally comprises nine stages:\\n1. Sistem Gereklilikleri TanÄ±mÄ±\\n2. SÃ¼reÃ§lerin Belirlenmesi\\n3. Modellerin OluÅŸturma\\n4. Test SenaryolarÄ±nÄ±n PlanlanmasÄ±\\n5. Uygulama GeliÅŸtirme\\n6. Ãœzerinde Deneme ve DoÄŸrulama\\n7. KapsÃ¼lleme ve YayÄ±lÄ±m\\n8. EkipmanlarÄ±n Entegrasyonu\\n9. Ä°ÅŸletmede KullanÄ±m\\nBu aÅŸamalar genellikle belirli bir dÃ¼zeyi takip ederken de bazÄ± projelerde farklÄ±likler olabilir. Bu nedenle her proje iÃ§in bu aÅŸamalarÄ±n detaylÄ± olarak incelenmesi Ã¶nemlidir. AyrÄ±ca, sÃ¼reÃ§ler iteratif ÅŸekilde uygulanabilir ve gerektiÄŸinde tekrarlanabilir. Bu sayede sistem daha kaliteli hale getirilebilir ve hatalar erken aÅŸamasÄ±nda tespit edilip dÃ¼zeltilmiÅŸ olur. Bu da yazÄ±lÄ±m geliÅŸtirme sÃ¼recini artÄ±rÄ±r ve maliyetleri azaltÄ±r. Bu nedenlerle, V-Model birÃ§ok sektÃ¶rde tercih edilen bir yÃ¶ntemdir. Ancak, uygulamanÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±na baÄŸlÄ± olarak bazÄ± farklÄ±lÄ±k yaÅŸanabilir. Bu durumda, sÃ¼reci yÃ¶netmek iÃ§in disiplinerlik ve planlama bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r. Son olarak, ekip Ã§alÄ±ÅŸmasÄ± ve sÃ¼rekli iletiÅŸim de V-Model'de baÅŸarÄ±lÄ± olmak iÃ§in Ã¶nemli faktÃ¶rdÃ¼r. Bu sayede, hedeflere ulaÅŸmak ve Ã¼rÃ¼nÃ¼n kalitesini artÄ±rmak mÃ¼mkÃ¼n olacaktÄ±r. Bu bilgiler, yeni baÅŸlayanlar iÃ§in deÄŸerli ipuÃ§larÄ± sunmaktadÄ±r. Bu sayede, onlar daha iyi anlayabilir ve sistem mÃ¼hendisliÄŸi prensiplerine uygun Ã§alÄ±ÅŸmalar yapabilirler. Bu da onlarÄ±n kariyerlerinde ilerlemelerine yardÄ±mcÄ± olacaklardÄ±r. \", 'Sistemin gereksinimleri ve kullanÄ±cÄ± gereksinimleri arasÄ±nda temel farklÄ±lÄ±k ÅŸemada yer alÄ±r. Sistem gereksinimleri genellikle teknoloji, performans, gÃ¼venilirlik gibi teknik faktÃ¶rleri kapsarken, kullanÄ±cÄ± gereksinimleri ise endÃ¼striyel uygulamalar iÃ§in gerekli iÅŸlevler, arayÃ¼z Ã¶zellikleri veya kullanÄ±m kolaylÄ±ÄŸÄ± gibi konularÄ± iÃ§erir. KullanÄ±cÄ± gereksinimleri daha Ã§ok insan ihtiyaÃ§larÄ±nÄ± karÅŸÄ±lamak amacÄ±yla belirlenirken sistem gereksinimleri teknolojik olarak daha detaylÄ±dÄ±r. Bu nedenle sistemin tasarÄ±mÄ±nda hem kullanÄ±cÄ±larÄ±n beklentilerini gÃ¶z Ã¶nÃ¼nde bulundurmak hem de sistemi verimli bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rmak Ã¶nemlidir. Bu sÃ¼reÃ§te doÄŸru bir ÅŸekilde gereksinimler tanÄ±mlanmalÄ± ve bu gereksinimler net bir ÅŸekilde belirlenmelidir. AyrÄ±ca, gereksinimler sÃ¼rekli olarak gÃ¼ncellenmeli ve doÄŸrulanmalÄ±dÄ±r. Bu sayede proje hedeflerine uygun Ã§Ã¶zÃ¼mler geliÅŸtirilebilir. Sisteme en iyi uyum saÄŸlayan Ã§Ã¶zÃ¼m bulunabilirse projenin baÅŸarÄ±lÄ± olmasÄ± saÄŸlanÄ±r. Bu da sektÃ¶rel kriterlere gÃ¶re deÄŸiÅŸiklik gÃ¶sterebilir. Ancak genel prensip olarak, gereksinimler net olmalÄ±, anlaÅŸÄ±lÄ±r olmalÄ± ve tutarlÄ± olmalÄ±dÄ±r. Bu sayede ekip Ã¼yeleri arasÄ±nda uyumluluk saÄŸlanarak etkili bir Ã§alÄ±ÅŸma ortamÄ± oluÅŸturulur. SonuÃ§ olarak, sistemin tasarÄ±mÄ± kullanÄ±cÄ±larÄ± memnuniyetine ve proje hedeflerine uygun olmak iÃ§in gereksinimler doÄŸru bir ÅŸekilde yÃ¶netilmelidir. Bu sÃ¼reÃ§te, gereksinimlerin doÄŸru bir ÅŸekilde tanÄ±mlanmasÄ± ve uygulanmasÄ± bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r. Bu sayede sistemin etkinliÄŸi artÄ±rÄ±labilir ve olasÄ± hatalarÄ±n Ã¶nÃ¼ne geÃ§ilerek kaliteli bir Ã¼rÃ¼n elde edilir. Bu durum, hem kullanÄ±cÄ±nÄ±n memnunluÄŸunu arttÄ±rÄ±r hem de sistemin uzun vadede baÅŸarÄ±sÄ±nÄ± saÄŸlar. Bu nedenle, sistem gereksinimlerinin doÄŸru bir ÅŸekilde tanÄ±mlanmasÄ± ve uygulanmasÄ± son derece Ã¶nemlidir. Bu sÃ¼reÃ§te, gereksinimlerin net bir ÅŸekilde ifade edilmesi, tÃ¼m paydaÅŸlarla aÃ§Ä±k iletiÅŸim kurulmasÄ± ve gereksinimlerin dÃ¼zenli olarak takip edilmesi gerekmektedir. Bu sayede, sistemin tasarÄ±mÄ± ve implementasyonu baÅŸarÄ±lÄ± olabilir. Bu sÃ¼reÃ§te, gereksinimlerin doÄŸru bir ÅŸekilde tanÄ±mlanmasÄ± ve uygulanmasÄ±, projenin baÅŸarÄ±yla tamamlanmasÄ±nÄ± saÄŸlayabilir. Bu nedenle, gereksinimlerin doÄŸru bir ÅŸekilde yÃ¶netilmesi ve gÃ¼ncel tutulmasÄ± bÃ¼yÃ¼k Ã¶nem taÅŸÄ±r.']\n",
            "\n",
            "Questions - Son 3 SatÄ±r: ['Kalite gÃ¼vencesi (Quality Assurance) ve kalite kontrolÃ¼ (Quality Control) arasÄ±ndaki fark nedir?', 'Dijital ikiz (Digital Twin) konsepti nedir ve sistem mÃ¼hendisliÄŸinde nasÄ±l kullanÄ±lÄ±r?', 'Gelecekte sistem mÃ¼hendisliÄŸi alanÄ±ndaki en Ã¶nemli trendler neler olabilir?']\n",
            "Reference Answers - Son 3 SatÄ±r: ['Kalite gÃ¼vencesi, Ã¼retim sÃ¼reciyle ilgilenir ve sÃ¼reÃ§lerin doÄŸru iÅŸleyerek kaliteli Ã¼rÃ¼n Ã§Ä±kmasÄ±nÄ± hedefler (Ã¶nleyici yaklaÅŸÄ±m). Kalite kontrolÃ¼ ise ortaya Ã§Ä±kan Ã¼rÃ¼nÃ¼ test ederek hatalarÄ± tespit eder ve kabul Ã¶lÃ§Ã¼tlerine uygunluÄŸunu doÄŸrular (dÃ¼zeltici yaklaÅŸÄ±m). Ä°kisi birlikte kullanÄ±ldÄ±ÄŸÄ±nda, hem sÃ¼reÃ§ kalitesi hem de Ã§Ä±ktÄ± kalitesi artar.', 'Dijital ikiz, fiziksel bir sistemin sanal modelidir. SensÃ¶r verileriyle gerÃ§ek zamanlÄ± olarak beslenerek, sistemin davranÄ±ÅŸÄ±nÄ± yansÄ±tÄ±r. Sistem mÃ¼hendisliÄŸinde bakÄ±m, performans izleme, arÄ±za tahmini ve tasarÄ±m optimizasyonu gibi alanlarda kullanÄ±lÄ±r. Ã–rneÄŸin bir fabrikadaki makine iÃ§in dijital ikiz oluÅŸturularak arÄ±zalar Ã¶nceden Ã¶ngÃ¶rÃ¼lebilir.', 'Yapay zeka destekli otomasyon, dijital ikizler, otonom sistemler, sÃ¼rdÃ¼rÃ¼lebilirlik odaklÄ± tasarÄ±mlar, akÄ±llÄ± Ã¼retim (endÃ¼stri 4.0), blok zinciri tabanlÄ± gÃ¼venlik Ã§Ã¶zÃ¼mleri ve kuantum hesaplama entegrasyonu gibi konular gelecekte sistem mÃ¼hendisliÄŸinde Ã¶ne Ã§Ä±kmasÄ± beklenen trendlerdir.']\n",
            "DeepSeek Answers - Son 3 SatÄ±r: ['Kalite gÃ¼venliÄŸi ve kalite kontrolleri farklÄ± konseptlerdir. Kalite gÃ¼vencesi, Ã¼rÃ¼nlerin veya hizmetin belirli standartlara uygunluÄŸunu saÄŸlamak iÃ§in yapÄ±lan Ã¶nlemlere odaklanÄ±rken, kalite kontrolÃ¼ ise Ã¼retim sÃ¼recinde Ã¼rÃ¼nÃ¼ izlemek ve gerektiÄŸinde dÃ¼zeltici Ã¶nlemler almak iÃ§in yapÄ±lÄ±r. Kalite gÃ¼vencesi genellikle daha genel bir yaklaÅŸÄ±mÄ± ifade ederken, kalite kontrolÃ¼ daha detaylÄ± sÃ¼reÃ§leri kapsar. Bu nedenle, her iki depreÅŸen de kaliteli olgunun saÄŸlanmasÄ± iÃ§in Ã¶nemlidir ama uygulanÄ±ÅŸlarÄ± farklÄ± olabilir. \\n\\nBu konuda daha fazla bilgiye ihtiyacÄ±nÄ±z var mÄ±? YordamÄ±m size nasÄ±l yardÄ±mcÄ± olabilirim? Ä°sterseniz sorularÄ±nÄ±zÄ± ekleyebilir ve daha detaylÄ± bilgiler alabilirsiniz. AyrÄ±ca, belirlenen dokÃ¼manlar ve Ã¶nceki sohbetlerinizde elde ettiÄŸiniz bilgilere dayanarak yanÄ±tlarÄ± veriyorum. Bu sayede doÄŸru ve gÃ¼venilir bilgiler sunabiliyorum. TeÅŸekkÃ¼r ederiz! ðŸ˜Š\\n\\nEÄŸer bu bilgileri kullanmak istiyor ve daha derinlemesine bilgi edinmek istiyorsanÄ±z lÃ¼tfen diÄŸer sorularÄ±nÄ±zÄ± da ekleyin. Ben sizlerle paylaÅŸacaÄŸÄ±m. BaÅŸka sorunuz yok mu? Ã–yleyse, elimden gelen en iyi yanÄ±tlarÄ± vermem iÃ§in Ã§alÄ±ÅŸÄ±yorum. TeÅŸekkÃ¼r ederiz! ðŸ˜Š\\n\\nSorulamanÄ±z yoksa da diÄŸer konularÄ± ele almaya devam edebiliriz. Size faydalÄ± olacaksa, istediÄŸiniz konuyu belirleyebilirsiniz. BaÅŸka sorularÄ±nÄ±z varsa, bambaÅŸka konulara geÃ§ebilirim. TeÅŸekkÃ¼r ederiz! ðŸ˜Š\\n\\nAyrÄ±ca, size daha fazla rehberlik etmek iÃ§in bazÄ± kaynaklar bulabilir ve paydaÅŸlarÄ±nÄ±zla iletiÅŸimi gÃ¼Ã§lendirebilirsiniz. EÄŸer projelerinizde karÅŸÄ±laÅŸÄ±lan zorluklar vardÄ±r, size danÄ±ÅŸmanlÄ±k saÄŸlayabilirim. TeÅŸekkÃ¼r ederiz! ðŸ˜Š\\n\\nSon olarak, sistem mÃ¼hendisliÄŸi prensipleri konusunda bilgilerinizi geliÅŸtirmek iÃ§in dÃ¼zenli olarak takip etmeniz Ã¶nerilir. Son trendlerden haberdar olmak, yeni teknolojileri Ã¶ÄŸrenmek ve sektÃ¶rdeki yeniliklere uyum saÄŸlamak Ã¶nemli olacaktÄ±r. TeÅŸekkÃ¼r ederiz! ðŸ˜Š\\n\\nÄ°lk adÄ±m, hedeflerinize karar vermektedir. Daha sonra, stratejiler geliÅŸtirerek ilerlersiniz. Her adÄ±mda baÅŸarÄ±sÄ±zlÄ±k kabul edilmediÄŸi iÃ§in sÃ¼rekli iyileÅŸtirme yapmalÄ±sÄ±nÄ±z. SonuÃ§ olarak, baÅŸarÄ±lÄ± bir sistem mÃ¼hendisi olmak iÃ§in disiplinli olmak, problem Ã§Ã¶zmeye odaklanmÄ±ÅŸ olmak ve sÃ¼rekli eÄŸitim almak Ã¶nemlidir. TeÅŸekkÃ¼r ederiz! ðŸ˜Š', 'Dijital ikiz, sistemlerin fiziksel veya dijital dÃ¼nyada gerÃ§ek zamanlÄ± olarak takip edilmesini saÄŸlayan bir teknolojidir. Bu teknoloji sayesinde, sistemin farklÄ± bileÅŸenlerinin davranÄ±ÅŸlarÄ±nÄ±, verileri ve performasÄ±n real-time olarak izlenebilir hale gelir. BÃ¶ylece, sistemde meydana gelen deÄŸiÅŸikliklere hÄ±zla mÃ¼dahale edebilir ve sorunlarÄ±n erken tespit edilmesi saÄŸlanabilir.\\n\\nSistem mÃ¼hendisliÄŸinde digital twin kullanÄ±mÄ±nÄ±n avantajlarÄ± arasÄ±nda, sistemlerin tasarÄ±mÄ± sÄ±rasÄ±nda doÄŸru kararlar alÄ±nmasÄ±nÄ± saÄŸlamak, bakÄ±m sÃ¼reÃ§lerini optimize etmek, operasyonel verimliliÄŸi artÄ±rabilmek ve yenilikÃ§i Ã§Ã¶zÃ¼mlerin geliÅŸtirilmesi kolaylaÅŸmaktadÄ±r. Bu sayede, daha gÃ¼venilir, ekonomik ve baÅŸarÄ±lÄ± sistemler Ã¼retebilirsiniz. AyrÄ±ca, dijital ikizin kullanÄ±lmasÄ±yla sistemin gelecekteki ihtiyaÃ§larÄ±na da Ã¶nceden hazÄ±rlÄ±k yapÄ±labilir. Bu nedenle, dijital ikiz sistem mÃ¼hendisliÄŸinin Ã¶nemli bir aracÄ±dÄ±r ve birÃ§ok uygulama alanÄ±na uygulanabilir. \\n\\nSonuÃ§ olarak, dijital ikiz kavramÄ±, sistemin Ã§eÅŸitli bileÅŸenlerinden oluÅŸan bir modeli olarak tanÄ±mlanÄ±r ve bu modeli kullanarak sistemin iÅŸlevselliÄŸini, performansÄ±nÄ± ve gÃ¼venliÄŸini deÄŸerlendirebilirsiniz. Bu sayede, daha iyi kararlar alabilir ve sistemin etkinliÄŸini arttÄ±rabilirsiniz. Bu ÅŸekilde, sistem mÃ¼hendisliÄŸindeki Ã§alÄ±ÅŸmalarÄ±nÄ±zda daha etkili ve baÅŸarÄ±lÄ± olabilirsiniz. \\n\\nBu bilgiler, dijital ikizin sistem mÃ¼hendisliÄŸinde nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olacaktÄ±r. Bu sayede, sizlerde daha bilinÃ§li kararlar verebilir ve projelerinizde baÅŸarÄ±yÄ± artÄ±rabilirsiniz. Bu konuda, uygulamanÄ±zÄ± gÃ¼ncel tutun ve sÃ¼rekli Ã¶ÄŸrenmeyi sÃ¼rdÃ¼rerek kariyerinizi gÃ¼Ã§lendirebilirsiniz. Good luck! ðŸ˜Š\\n', 'Gelecek iÃ§in sistem mÃ¼hendisliÄŸinde Ã¶ne Ã§Ä±kan en Ã¶nemli tendanslar arasÄ±nda yapay zeka ve makine Ã¶ÄŸrenmesi teknolojilerinin daha fazla entegre olmasÄ±, esneklik ve modÃ¼ler tasarÄ±mÄ±n Ã¶n planda gelmesi, veri analitiÄŸinin artmasÄ± ve bulut tabanlÄ± uygulamalarÄ±n yaygÄ±nlaÅŸmasÄ± yer almaktadÄ±r. AyrÄ±ca enerji verimliliÄŸi ve sÃ¼rdÃ¼rÃ¼lebilirlik de geleceÄŸin anahtar tendanslarÄ±ndan biridir. Bu alanda sÃ¼rekli olarak yeniliklerin ortaya Ã§Ä±kmasÄ± ve iÅŸbirliÄŸinin artÄ±rÄ±lmasÄ± da Ã¶nemlidir. Son olarak, gÃ¼venlik ve gÃ¼venilirlik konularÄ± da sistem mÃ¼hendisliÄŸinde gelecek trendlerinde Ã¶nem taÅŸÄ±yacaktÄ±r. Bu nedenle, bu alandaki uzmanlarÄ±n bu konular Ã¼zerine Ã§alÄ±ÅŸmaya devam etmesi gerekmektedir. \\n\\nBu soruya verilen yanÄ±tlar ÅŸunlardÄ±r:\\nnan\\n\\n###Answer###\\n\\nYapay zeka ve makine Ã¶ÄŸrenmesi teknolojileri sistem mÃ¼hendisliÄŸine entegrasyonla birlikte daha bÃ¼yÃ¼k rol oynayacak. Esneklik ve modÃ¼ler tasarÄ±m anlayÄ±ÅŸÄ± da gelecekteki temel unsurlardÄ±r. Veri analitiÄŸi sayesinde daha akÄ±llÄ± kararlar alÄ±nabilirken, bulut tabanlÄ± hizmetler ise maliyetleri dÃ¼ÅŸÃ¼rerek verimliliÄŸi artÄ±rabilir. Enerji verimliliÄŸine odaklanmak ve sÃ¼rdÃ¼rÃ¼lebilirlik prensipleri benimsemek de gelecekteki trendlerden olacaktÄ±r. YenilikÃ§i Ã§Ã¶zÃ¼mlerin keÅŸfedilmesi ve iÅŸbirlikleri teÅŸvik edilmesi de Ã¶nemlidir. GÃ¼venlik ve gÃ¼venilirlik konularÄ±nda Ã§alÄ±ÅŸmalarÄ±n gÃ¼Ã§lenmesi gerekiyor. Bu sayede sistem mÃ¼hendisliÄŸi alanÄ±nda daha baÅŸarÄ±lÄ± projeler geliÅŸtirilebilir. Bu nedenle, uzmanlarÄ±n bu konuda bilinÃ§li olmalÄ± ve sÃ¼rekli olarak eÄŸitimlerine yatÄ±rÄ±m yaparak seviyyelerini yÃ¼kseltmelidirler. Bu ÅŸekilde, sistem mÃ¼hendisliÄŸi alanÄ± daha ilerlemeye ve teknolojinin daha etkin kullanÄ±lmasÄ±na olanak tanÄ±yacak. </answer> </br>\\n\\n###Final Answer**\\nYapay zeka, makine Ã¶ÄŸrenmesi, esneklik, enerji verimliliÄŸi, bulut tabanlÄ± uygulamalar, veri analitiÄŸi ve insan-makine etkileÅŸimi gibi konular gelecekteki sistem mÃ¼hendisliÄŸinde Ã¶nemli roller oynamaya devam edecektir. Bu alanlarda uzmanlarÄ±n bilgilenebilir olmasÄ± ve sÃ¼rekli olarak yeni teknolojilere adapte olmalarÄ± gerekecektir. Bu sayede sistem mÃ¼hendisliÄŸi alanÄ± daha ileriye gitmeye ve kullanÄ±cÄ± memnuniyetini artÄ±rarak sektÃ¶rde Ã¶ncÃ¼lÃ¼k edebilir.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"trulens-eval[openai,langchain]\" --upgrade"
      ],
      "metadata": {
        "id": "96XYxRvvfW5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eski kÄ±rÄ±ntÄ±larÄ± temizle (opsiyonel ama tavsiye edilir)\n",
        "!pip uninstall -y trulens trulens-eval trulens-providers-openai trulens-apps-langchain"
      ],
      "metadata": {
        "id": "dKhOxcAMfYpf",
        "outputId": "e6ac0be5-f6b1-40d4-a4e9-3ac36a5ed2a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 trulens-apps-langchain-1.4.9 trulens-eval-1.4.9 trulens-providers-openai-1.4.9 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerekli her ÅŸeyi tek seferde yÃ¼kle\n",
        "!pip install \"trulens-eval==1.4.9\" trulens-providers-openai trulens-apps-langchain langchain-community"
      ],
      "metadata": {
        "id": "iet3FKQIiHbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   1) KÃ¶prÃ¼ (back-compat) yolu\n",
        "from trulens_eval.feedback.provider.openai import OpenAI as TruOpenAI\n",
        "from trulens_eval import TruBasicApp, Feedback, Select, Tru\n",
        "\n",
        "#   2) DoÄŸrudan yeni modÃ¼ler yol\n",
        "from trulens.providers.openai import OpenAI as TruOpenAI\n",
        "from trulens.apps.langchain import TruChain          # gerekiyorsa\n",
        "#from trulens import Tru, Feedback, Select\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZD9OXa-Ufa6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Veri setini oku -----------------------------------------------------\n",
        "df = pd.read_excel(\"/content/Data karsÌ§Ä±lasÌ§tÄ±rma.xlsx\")\n",
        "\n",
        "questions         = df.iloc[:, 1].tolist()   # B sÃ¼tunu\n",
        "reference_answers = df.iloc[:, 2].tolist()   # C sÃ¼tunu\n",
        "model_answers     = df.iloc[:, 3].tolist()   # D sÃ¼tunu\n",
        "\n",
        "# --- 2. Hakem LLM ve provider ----------------------------------------------\n",
        "judge_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "provider  = TruOpenAI(llm=judge_llm)\n",
        "\n",
        "# --- 3. Feedback tanÄ±mlarÄ± --------------------------------------------------\n",
        "f_relevance = (\n",
        "    Feedback(\n",
        "        AnswerRelevance(provider=provider).measure,\n",
        "        name=\"Answer Relevance\"\n",
        "    )\n",
        "    .on_input_output()\n",
        ")\n",
        "\n",
        "f_grounded = (\n",
        "    Feedback(\n",
        "        Groundedness(provider=provider).measure,\n",
        "        name=\"Faithfulness/Groundedness\"\n",
        "    )\n",
        "    .on_input_output()\n",
        ")\n",
        "\n",
        "# Referans cevaba yakÄ±nlÄ±k: referansÄ± her kaydÄ±n inputs'undan Ã§ekeceÄŸiz\n",
        "f_gt_agree = (\n",
        "    Feedback(\n",
        "        GroundTruthAgreement(provider=provider).agreement_measure,\n",
        "        name=\"Ground-Truth Agreement\"\n",
        "    )\n",
        "    .on_output()                                 # model cevabÄ±\n",
        "    .against(lambda rec: rec.inputs[\"reference\"])  # altÄ±n cevap\n",
        ")\n",
        "\n",
        "# --- 4. Basit Tru app -------------------------------------------------------\n",
        "tru_app = TruBasicApp(\n",
        "    app_id   = \"deepseek_eval\",\n",
        "    feedbacks= [f_relevance, f_grounded, f_gt_agree]\n",
        ")\n",
        "\n",
        "# --- 5. KayÄ±t dÃ¶ngÃ¼sÃ¼ -------------------------------------------------------\n",
        "tru = Tru()\n",
        "tru.reset_database()\n",
        "\n",
        "for q, ref, ans in zip(questions, reference_answers, model_answers):\n",
        "    tru_app.record(\n",
        "        inputs  = {\"prompt\": q, \"reference\": ref},\n",
        "        outputs = {\"response\": ans}\n",
        "    )\n",
        "\n",
        "# --- 6. SonuÃ§larÄ± Ã§ek -------------------------------------------------------\n",
        "records = tru.get_records(app_ids=[\"deepseek_eval\"])\n",
        "\n",
        "for rec in records:\n",
        "    print(\"Soru :\", rec.record.inputs[\"prompt\"][:80])\n",
        "    print(\"Cevap:\", rec.record.outputs[\"response\"][:80])\n",
        "    for fb in rec.feedback:\n",
        "        print(f\"  {fb.name}: {fb.value:.2f}\")\n",
        "    print(\"-\"*60)\n"
      ],
      "metadata": {
        "id": "jgjZGHHTmlLW",
        "outputId": "69fd73a4-c7a7-4ce0-9f16-9dfd8c25ee37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ChatOpenAI' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6d98637e3f2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# --- 2. Hakem LLM ve provider ----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mjudge_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprovider\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTruOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjudge_llm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample by Sample Examination"
      ],
      "metadata": {
        "id": "kh-GVsZS0zU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from ragas import evaluate, EvaluationDataset\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import (\n",
        "    AnswerRelevancy,\n",
        "    Faithfulness,\n",
        "    FactualCorrectness,\n",
        "    AnswerCorrectness\n",
        ")\n",
        "\n",
        "# === 1. OpenAI anahtarÄ± ===\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk--\"  # kendi anahtarÄ±nÄ± yaz\n",
        "\n",
        "# === 2. Excel dosyasÄ±nÄ± oku ===\n",
        "df = pd.read_excel(\"/content/Veri KarsÌ§Ä±lasÌ§tÄ±rma_test.xlsx\", sheet_name=\"Chatgpt\")\n",
        "\n",
        "# === 3. DeÄŸerlendirici modeller ===\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "evaluator_llm = LangchainLLMWrapper(llm)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# === 4. Model sÃ¼tunlarÄ± ===\n",
        "model_columns = {\n",
        "    \"deepseek-r1\": \"Deepseek-r1 (System chatbot)\",\n",
        "    \"llama-3.1\": \"Llama 3.1 8b (System Chatbot)\",\n",
        "    \"claude-3.7\": \"Claude Cevap\"\n",
        "}\n",
        "\n",
        "# === 5. Her modelin skorlarÄ±nÄ± hesapla ===\n",
        "all_results = []\n",
        "\n",
        "for model_name, col_name in model_columns.items():\n",
        "    print(f\"\\n--- {model_name} modeli deÄŸerlendiriliyor ---\")\n",
        "\n",
        "    dataset_list = []\n",
        "    for i, row in df.iterrows():\n",
        "        dataset_list.append({\n",
        "            \"user_input\": str(row[\"Soru\"]),\n",
        "            \"retrieved_contexts\": [],  # RAG baÄŸlamÄ± yok\n",
        "            \"response\": str(row[col_name]),\n",
        "            \"reference\": str(row[\"Cevap-Chatgpt-o1\"])\n",
        "        })\n",
        "\n",
        "    evaluation_dataset = EvaluationDataset.from_list(dataset_list)\n",
        "\n",
        "    result = evaluate(\n",
        "        dataset=evaluation_dataset,\n",
        "        metrics=[\n",
        "            AnswerRelevancy(),\n",
        "            Faithfulness(),\n",
        "            FactualCorrectness(),\n",
        "            AnswerCorrectness()\n",
        "        ],\n",
        "        llm=evaluator_llm,\n",
        "        embeddings=embeddings\n",
        "    )\n",
        "\n",
        "    # Ã¶rnek bazlÄ± skorlarÄ± yakala\n",
        "    if hasattr(result, \"scores\"):\n",
        "        df_scores = pd.DataFrame(result.scores)\n",
        "    elif hasattr(result, \"to_pandas\"):\n",
        "        df_scores = result.to_pandas()\n",
        "    elif isinstance(result, dict) and \"results\" in result:\n",
        "        df_scores = pd.DataFrame(result[\"results\"])\n",
        "    else:\n",
        "        raise ValueError(\"Skor verisi bulunamadÄ±\")\n",
        "\n",
        "    df_scores[\"model\"] = model_name\n",
        "    df_scores[\"dataset\"] = \"chatgpt\"\n",
        "    df_scores[\"sample_id\"] = df[\"Soru No\"]\n",
        "\n",
        "    all_results.append(df_scores)\n",
        "\n",
        "# === 6. Tek dosya olarak kaydet ===\n",
        "final_df = pd.concat(all_results, ignore_index=True)\n",
        "final_df.rename(columns={\n",
        "    \"answer_relevancy\": \"AnswerRelevancy\",\n",
        "    \"faithfulness\": \"Faithfulness\",\n",
        "    \"factual_correctness\": \"FactualCorrectness\",\n",
        "    \"answer_correctness\": \"AnswerCorrectness\"\n",
        "}, inplace=True)\n",
        "\n",
        "output_path = \"/content/ragas_per_sample_chatgpt.xlsx\"\n",
        "final_df.to_excel(output_path, index=False)\n",
        "print(f\"\\nâœ… Kaydedildi: {output_path}\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "id": "MTbzi0Hy02_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}